#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
CJå•†å“æŸ¥è¯¢å·¥å…·
ä½¿ç”¨GraphQL APIè·å–å¹¿å‘Šå•†å•†å“
"""

import os
import json
import argparse
from pathlib import Path
from datetime import datetime
import requests
from dotenv import load_dotenv
from loguru import logger # å¯¼å…¥ loguru logger

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—è®°å½•å™¨ - Loguru åœ¨ main.py ä¸­é…ç½®ï¼Œè¿™é‡Œä¸éœ€è¦å•ç‹¬é…ç½®
# # æ—¥å¿—çº§åˆ«å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡ LOG_LEVEL æ§åˆ¶ï¼Œé»˜è®¤ä¸º INFO
# # æ—¥å¿—æ ¼å¼åŒ…å«æ—¶é—´ã€çº§åˆ«ã€æ¨¡å—åã€å‡½æ•°åå’Œæ¶ˆæ¯
# logging.basicConfig(
#     level=os.getenv('LOG_LEVEL', 'INFO').upper(),
#     format='%(asctime)s - %(levelname)s - %(name)s - %(funcName)s - %(message)s'
# )
# logger = logging.getLogger(__name__) # ä¸ºå½“å‰æ¨¡å—åˆ›å»ºä¸€ä¸ªæ—¥å¿—è®°å½•å™¨å®ä¾‹

# APIé…ç½®
CJ_API_ENDPOINT = os.getenv('CJ_API_ENDPOINT', 'https://ads.api.cj.com/query')
CJ_API_TOKEN = os.getenv('CJ_API_TOKEN')
COMPANY_ID = os.getenv('CJ_CID') or os.getenv('BRAND_CID') or '7520009'
CJ_PID = os.getenv('CJ_PID', '')

def get_products_by_advertiser(advertiser_id, limit=50, output_raw_response=False):
    """
    æ ¹æ®å¹¿å‘Šå•†IDæŸ¥è¯¢å•†å“
    
    Args:
        advertiser_id (str): å¹¿å‘Šå•†ID
        limit (int): è¿”å›ç»“æœæ•°é‡é™åˆ¶
        output_raw_response (bool): æ˜¯å¦å°†åŸå§‹å“åº”ä¿å­˜åˆ°æ–‡ä»¶
        
    Returns:
        dict: æŸ¥è¯¢ç»“æœ
    """
    # æ„å»ºGraphQLæŸ¥è¯¢
    # æ³¨æ„ï¼šæ ¹æ® CJ API çš„è§„åˆ™ï¼Œå½“ä½¿ç”¨ Publisher Company ID æŸ¥è¯¢ç‰¹å®šå¹¿å‘Šå•†çš„äº§å“æ—¶ï¼Œ
    # éœ€è¦ä½¿ç”¨ partnerIds å‚æ•°ï¼Œè€Œä¸æ˜¯ advertiserIdsã€‚
    query = f"""
    {{
      products(companyId: "{COMPANY_ID}", partnerIds: ["{advertiser_id}"], limit: {limit}) {{
        totalCount
        count
        resultList {{
          advertiserId
          advertiserName
          id
          title
          description
          price {{
            amount
            currency
          }}
          imageLink
          link
          brand
          ... on Shopping {{
            gtin
            mpn
            condition
            availability
            color
            size
            material
            gender
            ageGroup
            salePrice {{
              amount
              currency
            }}
            googleProductCategory {{
              id
              name
            }}
            productType
            customLabel0
            customLabel1
            shipping {{
              price {{
                amount
                currency
              }}
              country
            }}
          }}
          lastUpdated
        }}
      }}
    }}
    """
    
    headers = {
        'Authorization': f'Bearer {CJ_API_TOKEN}',
        'Content-Type': 'application/json'
    }
    
    body = json.dumps({'query': query})
    
    try:
        logger.info(f'æ­£åœ¨æŸ¥è¯¢å¹¿å‘Šå•† {advertiser_id} çš„å•†å“...')
        
        response = requests.post(CJ_API_ENDPOINT, headers=headers, data=body)
        
        # è·å–åŸå§‹å“åº”æ–‡æœ¬
        response_text = response.text
        logger.debug('--- API åŸå§‹å“åº”æ–‡æœ¬ ---')
        logger.debug(response_text)
        logger.debug('--- API åŸå§‹å“åº”æ–‡æœ¬ç»“æŸ ---')
        
        # å¦‚æœéœ€è¦ï¼Œä¿å­˜åŸå§‹å“åº”åˆ°æ–‡ä»¶
        if output_raw_response:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_dir = Path("output") / "raw_responses"
            output_dir.mkdir(parents=True, exist_ok=True)
            response_file = output_dir / f"cj_raw_response_{advertiser_id}_{timestamp}.json"
            
            with open(response_file, 'w', encoding='utf-8') as f:
                f.write(response_text)
            logger.info(f"å·²ä¿å­˜CJ APIåŸå§‹å“åº”åˆ°æ–‡ä»¶: {response_file}")
        
        # æ£€æŸ¥HTTPçŠ¶æ€ç 
        response.raise_for_status()
        
        # è§£æJSONå“åº”
        try:
            json_data = response.json()
            logger.debug('--- JSON è§£æç»“æœ ---')
            logger.debug(json.dumps(json_data, indent=2, ensure_ascii=False))
            logger.debug('--- JSON è§£æç»“æŸ ---')
            return json_data
        except json.JSONDecodeError as parse_error:
            logger.error(f'è§£æ JSON å“åº”å‡ºé”™: {parse_error}')
            logger.error(f'æ— æ³•è§£æçš„å“åº”æ–‡æœ¬: {response_text}')
            raise Exception('æ— æ³•è§£æ API è¿”å›çš„ JSON æ•°æ®')
            
    except requests.exceptions.RequestException as error:
        logger.error(f'æŸ¥è¯¢å¹¿å‘Šå•† {advertiser_id} çš„å•†å“æ—¶å‡ºé”™:')
        if hasattr(error, 'response'):
            logger.error(f'APIå“åº”çŠ¶æ€: {error.response.status_code}')
            try:
                logger.error(f'APIè¿”å›çš„é”™è¯¯è¯¦æƒ…: {json.dumps(error.response.json(), indent=2, ensure_ascii=False)}')
            except:
                logger.error(f'APIè¿”å›çš„åŸå§‹å†…å®¹: {error.response.text}')
        else:
            logger.error(f'åŸå§‹é”™è¯¯: {error}')
        raise error

def search_products(keyword, limit=50):
    """
    æ ¹æ®å…³é”®è¯æœç´¢å•†å“
    
    Args:
        keyword (str): æœç´¢å…³é”®è¯
        limit (int): è¿”å›ç»“æœæ•°é‡é™åˆ¶
        
    Returns:
        dict: æŸ¥è¯¢ç»“æœ
    """
    # æ„å»ºGraphQLæŸ¥è¯¢ - ä½¿ç”¨productså­—æ®µå¹¶é€šè¿‡å®¢æˆ·ç«¯è¿‡æ»¤
    query = f"""
    {{
      products(companyId: "{COMPANY_ID}", limit: {limit}) {{
        totalCount
        count
        resultList {{
          id
          title
          description
          price {{
            amount
            currency
          }}
          imageLink
          link
          advertiserName
          advertiserId
          brand
          ... on Shopping {{
            availability
            condition
            gtin
            mpn
            color
            size
            material
            gender
            ageGroup
            salePrice {{
              amount
              currency
            }}
            googleProductCategory {{
              id
              name
            }}
            productType
            customLabel0
            customLabel1
            shipping {{
              price {{
                amount
                currency
              }}
              country
            }}
          }}
          lastUpdated
        }}
      }}
    }}
    """
    
    headers = {
        'Authorization': f'Bearer {CJ_API_TOKEN}',
        'Content-Type': 'application/json'
    }
    
    body = json.dumps({'query': query})
    
    try:
        logger.info(f'æ­£åœ¨æœç´¢å…³é”®è¯ "{keyword}" çš„å•†å“...')
        
        response = requests.post(CJ_API_ENDPOINT, headers=headers, data=body)
        
        # è·å–åŸå§‹å“åº”æ–‡æœ¬
        response_text = response.text
        logger.debug('--- API åŸå§‹å“åº”æ–‡æœ¬ (æœç´¢) ---')
        logger.debug(response_text)
        logger.debug('--- API åŸå§‹å“åº”æ–‡æœ¬ç»“æŸ (æœç´¢) ---')
        
        response.raise_for_status()
        
        # è§£æJSONå“åº”
        try:
            json_data = response.json()
            logger.debug('--- JSON è§£æç»“æœ (æœç´¢) ---')
            logger.debug(json.dumps(json_data, indent=2, ensure_ascii=False))
            logger.debug('--- JSON è§£æç»“æŸ (æœç´¢) ---')
            
            # åœ¨å®¢æˆ·ç«¯è¿›è¡Œå…³é”®è¯è¿‡æ»¤
            if json_data and 'data' in json_data and 'products' in json_data['data']:
                products_data = json_data['data']['products']
                all_products = products_data.get('resultList', [])
                
                # è¿‡æ»¤åŒ…å«å…³é”®è¯çš„å•†å“
                keyword_lower = keyword.lower()
                filtered_products = []
                
                for product in all_products:
                    title = (product.get('title', '') or '').lower()
                    description = (product.get('description', '') or '').lower()
                    brand = (product.get('brand', '') or '').lower()
                    
                    if (keyword_lower in title or 
                        keyword_lower in description or 
                        keyword_lower in brand):
                        filtered_products.append(product)
                
                # æ›´æ–°ç»“æœ
                json_data['data']['products']['resultList'] = filtered_products[:limit]
                json_data['data']['products']['count'] = len(filtered_products[:limit])
                
                logger.info(f'ä» {len(all_products)} ä¸ªå•†å“ä¸­ç­›é€‰å‡º {len(filtered_products)} ä¸ªåŒ¹é… "{keyword}" çš„å•†å“')
            
            return json_data
        except json.JSONDecodeError as parse_error:
            logger.error(f'è§£æ JSON å“åº”å‡ºé”™ (æœç´¢å…³é”®è¯: {keyword}): {parse_error}')
            logger.error(f'æ— æ³•è§£æçš„å“åº”æ–‡æœ¬ (æœç´¢): {response_text}')
            raise Exception('æ— æ³•è§£æ API è¿”å›çš„ JSON æ•°æ® (æœç´¢)')
            
    except requests.exceptions.RequestException as error:
        logger.error(f'æœç´¢å•†å“å‡ºé”™ (å…³é”®è¯: {keyword}): {error}')
        if hasattr(error, 'response'):
            logger.error(f'APIå“åº”çŠ¶æ€ (æœç´¢): {error.response.status_code}')
            try:
                logger.error(f'GraphQLé”™è¯¯ (æœç´¢): {json.dumps(error.response.json(), indent=2, ensure_ascii=False)}')
            except:
                logger.error(f'APIè¿”å›çš„åŸå§‹å†…å®¹ (æœç´¢): {error.response.text}')
        else:
            logger.error(f'åŸå§‹é”™è¯¯ (æœç´¢å…³é”®è¯: {keyword}): {error}')
        raise error

def get_joined_advertiser_products(limit=50):
    """
    è·å–å·²åŠ å…¥å¹¿å‘Šå•†çš„å•†å“
    
    Args:
        limit (int): è¿”å›ç»“æœæ•°é‡é™åˆ¶
        
    Returns:
        dict: æŸ¥è¯¢ç»“æœ
    """
    # æ„å»ºGraphQLæŸ¥è¯¢ - ä½¿ç”¨productså­—æ®µè€Œä¸æ˜¯productSearch
    query = f"""
    {{
      products(companyId: "{COMPANY_ID}", limit: {limit}) {{
        totalCount
        count
        resultList {{
          id
          title
          description
          price {{
            amount
            currency
          }}
          imageLink
          link
          advertiserName
          advertiserId
          brand
          ... on Shopping {{
            availability
            condition
            gtin
            mpn
            color
            size
            material
            gender
            ageGroup
            salePrice {{
              amount
              currency
            }}
            googleProductCategory {{
              id
              name
            }}
            productType
            customLabel0
            customLabel1
            shipping {{
              price {{
                amount
                currency
              }}
              country
            }}
          }}
          lastUpdated
        }}
      }}
    }}
    """
    
    headers = {
        'Authorization': f'Bearer {CJ_API_TOKEN}',
        'Content-Type': 'application/json'
    }
    
    body = json.dumps({'query': query})
    
    try:
        logger.info('æ­£åœ¨æŸ¥è¯¢å·²åŠ å…¥å¹¿å‘Šå•†çš„å•†å“...')
        
        response = requests.post(CJ_API_ENDPOINT, headers=headers, data=body)

        # è·å–åŸå§‹å“åº”æ–‡æœ¬
        response_text = response.text
        logger.debug('--- API åŸå§‹å“åº”æ–‡æœ¬ (å·²åŠ å…¥å¹¿å‘Šå•†) ---')
        logger.debug(response_text)
        logger.debug('--- API åŸå§‹å“åº”æ–‡æœ¬ç»“æŸ (å·²åŠ å…¥å¹¿å‘Šå•†) ---')

        response.raise_for_status()
        
        # è§£æJSONå“åº”
        try:
            json_data = response.json()
            logger.debug('--- JSON è§£æç»“æœ (å·²åŠ å…¥å¹¿å‘Šå•†) ---')
            logger.debug(json.dumps(json_data, indent=2, ensure_ascii=False))
            logger.debug('--- JSON è§£æç»“æŸ (å·²åŠ å…¥å¹¿å‘Šå•†) ---')
            return json_data
        except json.JSONDecodeError as parse_error:
            logger.error(f'è§£æ JSON å“åº”å‡ºé”™ (å·²åŠ å…¥å¹¿å‘Šå•†): {parse_error}')
            logger.error(f'æ— æ³•è§£æçš„å“åº”æ–‡æœ¬ (å·²åŠ å…¥å¹¿å‘Šå•†): {response_text}')
            raise Exception('æ— æ³•è§£æ API è¿”å›çš„ JSON æ•°æ® (å·²åŠ å…¥å¹¿å‘Šå•†)')
            
    except requests.exceptions.RequestException as error:
        logger.error(f'æŸ¥è¯¢å·²åŠ å…¥å¹¿å‘Šå•†å•†å“å‡ºé”™: {error}')
        if hasattr(error, 'response'):
            logger.error(f'APIå“åº”çŠ¶æ€ (å·²åŠ å…¥å¹¿å‘Šå•†): {error.response.status_code}')
            try:
                logger.error(f'GraphQLé”™è¯¯ (å·²åŠ å…¥å¹¿å‘Šå•†): {json.dumps(error.response.json(), indent=2, ensure_ascii=False)}')
            except:
                logger.error(f'APIè¿”å›çš„åŸå§‹å†…å®¹ (å·²åŠ å…¥å¹¿å‘Šå•†): {error.response.text}')
        else:
            logger.error(f'åŸå§‹é”™è¯¯ (å·²åŠ å…¥å¹¿å‘Šå•†): {error}')
        raise error

def get_joined_advertisers(limit=100):
    """
    è·å–å·²åŠ å…¥çš„å¹¿å‘Šå•†åˆ—è¡¨
    
    Args:
        limit (int): è¿”å›ç»“æœæ•°é‡é™åˆ¶
        
    Returns:
        dict: å¹¿å‘Šå•†åˆ—è¡¨
    """
    # æ„å»ºGraphQLæŸ¥è¯¢ - è·å–å•†å“ä½†åªæå–å¹¿å‘Šå•†ä¿¡æ¯
    query = f"""
    {{
      products(companyId: "{COMPANY_ID}", limit: {limit}) {{
        totalCount
        count
        resultList {{
          advertiserId
          advertiserName
          brand
        }}
      }}
    }}
    """
    
    headers = {
        'Authorization': f'Bearer {CJ_API_TOKEN}',
        'Content-Type': 'application/json'
    }
    
    body = json.dumps({'query': query})
    
    try:
        logger.info(f'æ­£åœ¨è·å–å·²åŠ å…¥çš„å¹¿å‘Šå•†åˆ—è¡¨ (é™åˆ¶: {limit})...')
        
        response = requests.post(CJ_API_ENDPOINT, headers=headers, data=body)
        response.raise_for_status()
        
        json_data = response.json()
        
        if json_data and 'data' in json_data and 'products' in json_data['data']:
            products_data = json_data['data']['products']
            all_products = products_data.get('resultList', [])
            
            # æå–å”¯ä¸€çš„å¹¿å‘Šå•†ä¿¡æ¯
            advertisers_dict = {}
            for product in all_products:
                advertiser_id = product.get('advertiserId')
                advertiser_name = product.get('advertiserName')
                brand = product.get('brand')
                
                if advertiser_id and advertiser_name:
                    if advertiser_id not in advertisers_dict:
                        advertisers_dict[advertiser_id] = {
                            'id': advertiser_id,
                            'name': advertiser_name,
                            'brands': set()
                        }
                    
                    # æ·»åŠ å“ç‰Œä¿¡æ¯
                    if brand and brand != advertiser_name:
                        advertisers_dict[advertiser_id]['brands'].add(brand)
            
            # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ï¼Œå¹¶å°†setè½¬æ¢ä¸ºlist
            advertisers_list = []
            for advertiser_info in advertisers_dict.values():
                advertiser_info['brands'] = list(advertiser_info['brands'])
                advertisers_list.append(advertiser_info)
            
            # æŒ‰å¹¿å‘Šå•†åç§°æ’åº
            advertisers_list.sort(key=lambda x: x['name'])
            
            logger.info(f'æˆåŠŸè·å–åˆ° {len(advertisers_list)} ä¸ªå·²åŠ å…¥çš„å¹¿å‘Šå•†')
            
            return {
                'advertisers': advertisers_list,
                'total_count': len(advertisers_list)
            }
        else:
            error_info = json_data.get('errors') if json_data else "No data returned"
            logger.error(f'è·å–å¹¿å‘Šå•†åˆ—è¡¨å¤±è´¥ã€‚é”™è¯¯: {error_info}')
            return {'advertisers': [], 'total_count': 0}
            
    except requests.exceptions.RequestException as error:
        logger.error(f'è·å–å¹¿å‘Šå•†åˆ—è¡¨å‡ºé”™: {error}')
        if hasattr(error, 'response'):
            logger.error(f'APIå“åº”çŠ¶æ€: {error.response.status_code}')
            try:
                logger.error(f'APIè¿”å›çš„é”™è¯¯è¯¦æƒ…: {json.dumps(error.response.json(), indent=2, ensure_ascii=False)}')
            except:
                logger.error(f'APIè¿”å›çš„åŸå§‹å†…å®¹: {error.response.text}')
        raise error

def get_all_advertisers_via_lookup_api():
    """
    ä½¿ç”¨CJ Advertiser Lookup REST APIè·å–æ‰€æœ‰å·²åŠ å…¥çš„å¹¿å‘Šå•†
    
    Returns:
        dict: å¹¿å‘Šå•†åˆ—è¡¨
    """
    # CJ Advertiser Lookup APIç«¯ç‚¹
    lookup_url = "https://advertiser-lookup.api.cj.com/v3/advertiser-lookup"
    
    headers = {
        'Authorization': f'Bearer {CJ_API_TOKEN}',
        'Accept': 'application/xml',  # CJ APIé€šå¸¸è¿”å›XMLæ ¼å¼
        'User-Agent': 'Mozilla/5.0 (compatible; CJ-API-Client/1.0)'
    }
    
    params = {
        'cid': COMPANY_ID,
        'relationship-status': 'joined',  # åªè·å–å·²åŠ å…¥çš„å¹¿å‘Šå•†
        'records-per-page': 100  # æ¯é¡µæœ€å¤š100æ¡è®°å½•
    }
    
    try:
        logger.info('æ­£åœ¨é€šè¿‡Advertiser Lookup APIè·å–å·²åŠ å…¥çš„å¹¿å‘Šå•†åˆ—è¡¨...')
        
        response = requests.get(lookup_url, headers=headers, params=params)
        response.raise_for_status()
        
        # æ£€æŸ¥å“åº”å†…å®¹ç±»å‹
        content_type = response.headers.get('content-type', '')
        logger.debug(f'APIå“åº”å†…å®¹ç±»å‹: {content_type}')
        logger.debug(f'APIå“åº”çŠ¶æ€ç : {response.status_code}')
        
        # è§£æå“åº”
        if 'application/xml' in content_type or 'text/xml' in content_type:
            # è§£æXMLå“åº”
            try:
                import xml.etree.ElementTree as ET
                root = ET.fromstring(response.text)
                logger.debug(f'APIå“åº”XML: {response.text[:1000]}...')
                
                # å¤„ç†CJ API XMLå“åº”æ ¼å¼
                advertisers_list = []
                
                # æŸ¥æ‰¾æ‰€æœ‰advertiserå…ƒç´ 
                for advertiser_elem in root.findall('.//{http://api.cj.com}advertiser'):
                    advertiser_info = {
                        'id': advertiser_elem.get('advertiser-id', ''),
                        'name': advertiser_elem.get('advertiser-name', ''),
                        'website': '',
                        'category': '',
                        'relationship_status': advertiser_elem.get('relationship-status', ''),
                        'seven_day_epc': advertiser_elem.get('seven-day-epc', ''),
                        'three_month_epc': advertiser_elem.get('three-month-epc', '')
                    }
                    
                    # è·å–åˆ†ç±»ä¿¡æ¯
                    category_elem = advertiser_elem.find('.//{http://api.cj.com}category')
                    if category_elem is not None:
                        advertiser_info['category'] = category_elem.get('name', '')
                        advertiser_info['website'] = category_elem.get('parent', '')
                    
                    if advertiser_info['id'] and advertiser_info['name']:
                        advertisers_list.append(advertiser_info)
                        
            except ET.ParseError as e:
                logger.error(f'XMLè§£æé”™è¯¯: {e}')
                logger.debug(f'æ— æ³•è§£æçš„XML: {response.text[:500]}...')
                advertisers_list = []
                
        elif 'application/json' in content_type:
            # ä¿ç•™JSONå¤„ç†ä½œä¸ºå¤‡é€‰
            json_data = response.json()
            logger.debug(f'APIå“åº”æ•°æ®: {json.dumps(json_data, indent=2, ensure_ascii=False)}')
            
            # å¤„ç†CJ APIå“åº”æ ¼å¼
            advertisers_list = []
            if 'cj:advertisers' in json_data:
                cj_advertisers = json_data['cj:advertisers']
                if 'cj:advertiser' in cj_advertisers:
                    advertisers_data = cj_advertisers['cj:advertiser']
                    
                    # ç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼
                    if not isinstance(advertisers_data, list):
                        advertisers_data = [advertisers_data]
                    
                    for advertiser in advertisers_data:
                        advertiser_info = {
                            'id': str(advertiser.get('cj:advertiser-id', '')),
                            'name': advertiser.get('cj:advertiser-name', ''),
                            'website': advertiser.get('cj:primary-category', {}).get('cj:parent', ''),
                            'category': advertiser.get('cj:primary-category', {}).get('cj:name', ''),
                            'relationship_status': advertiser.get('cj:relationship-status', ''),
                            'seven_day_epc': advertiser.get('cj:seven-day-epc', ''),
                            'three_month_epc': advertiser.get('cj:three-month-epc', '')
                        }
                        advertisers_list.append(advertiser_info)
            
            logger.info(f'é€šè¿‡Lookup APIæˆåŠŸè·å–åˆ° {len(advertisers_list)} ä¸ªå·²åŠ å…¥çš„å¹¿å‘Šå•†')
            
            return {
                'advertisers': advertisers_list,
                'total_count': len(advertisers_list),
                'source': 'lookup_api'
            }
        else:
            # å¤„ç†éJSONå“åº”
            logger.warning(f'APIè¿”å›éJSONå“åº”ï¼Œå†…å®¹ç±»å‹: {content_type}')
            logger.debug(f'å“åº”å†…å®¹: {response.text[:500]}...')
            return {'advertisers': [], 'total_count': 0, 'source': 'lookup_api', 'error': 'Non-JSON response'}
            
    except requests.exceptions.RequestException as error:
        logger.error(f'é€šè¿‡Lookup APIè·å–å¹¿å‘Šå•†åˆ—è¡¨å‡ºé”™: {error}')
        if hasattr(error, 'response') and error.response is not None:
            logger.error(f'APIå“åº”çŠ¶æ€: {error.response.status_code}')
            logger.error(f'APIå“åº”å†…å®¹: {error.response.text}')
        return {'advertisers': [], 'total_count': 0, 'source': 'lookup_api', 'error': str(error)}

def get_advertisers_enhanced(limit=200):
    """
    å¢å¼ºç‰ˆå¹¿å‘Šå•†è·å–ï¼šåŒæ—¶ä½¿ç”¨GraphQLå’ŒREST API
    
    Args:
        limit (int): GraphQLæŸ¥è¯¢çš„å•†å“é™åˆ¶
        
    Returns:
        dict: åˆå¹¶åçš„å¹¿å‘Šå•†åˆ—è¡¨
    """
    logger.info('å¼€å§‹å¢å¼ºç‰ˆå¹¿å‘Šå•†æŸ¥è¯¢...')
    
    # æ–¹æ³•1: é€šè¿‡GraphQLè·å–ï¼ˆä»å•†å“ä¸­æå–ï¼‰
    graphql_data = get_joined_advertisers(limit)
    graphql_advertisers = graphql_data.get('advertisers', [])
    
    # æ–¹æ³•2: é€šè¿‡REST APIè·å–
    rest_data = get_all_advertisers_via_lookup_api()
    rest_advertisers = rest_data.get('advertisers', [])
    
    # åˆå¹¶ä¸¤ä¸ªæ•°æ®æº
    combined_advertisers = {}
    
    # æ·»åŠ GraphQLè·å–çš„å¹¿å‘Šå•†
    for advertiser in graphql_advertisers:
        advertiser_id = advertiser['id']
        combined_advertisers[advertiser_id] = {
            'id': advertiser_id,
            'name': advertiser['name'],
            'brands': advertiser.get('brands', []),
            'source': 'graphql'
        }
    
    # æ·»åŠ REST APIè·å–çš„å¹¿å‘Šå•†ï¼Œè¡¥å……ä¿¡æ¯
    for advertiser in rest_advertisers:
        advertiser_id = advertiser['id']
        if advertiser_id in combined_advertisers:
            # æ›´æ–°å·²æœ‰çš„å¹¿å‘Šå•†ä¿¡æ¯
            combined_advertisers[advertiser_id].update({
                'website': advertiser.get('website', ''),
                'category': advertiser.get('category', ''),
                'relationship_status': advertiser.get('relationship_status', ''),
                'seven_day_epc': advertiser.get('seven_day_epc', ''),
                'three_month_epc': advertiser.get('three_month_epc', ''),
                'source': 'both'
            })
        else:
            # æ·»åŠ æ–°çš„å¹¿å‘Šå•†
            combined_advertisers[advertiser_id] = {
                'id': advertiser_id,
                'name': advertiser['name'],
                'brands': [],
                'website': advertiser.get('website', ''),
                'category': advertiser.get('category', ''),
                'relationship_status': advertiser.get('relationship_status', ''),
                'seven_day_epc': advertiser.get('seven_day_epc', ''),
                'three_month_epc': advertiser.get('three_month_epc', ''),
                'source': 'rest_api'
            }
    
    # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ’åº
    final_advertisers = list(combined_advertisers.values())
    final_advertisers.sort(key=lambda x: x['name'])
    
    logger.info(f'å¢å¼ºç‰ˆæŸ¥è¯¢å®Œæˆ: GraphQLè·å– {len(graphql_advertisers)} ä¸ª, REST APIè·å– {len(rest_advertisers)} ä¸ª, åˆå¹¶åå…± {len(final_advertisers)} ä¸ªå¹¿å‘Šå•†')
    
    return {
        'advertisers': final_advertisers,
        'total_count': len(final_advertisers),
        'graphql_count': len(graphql_advertisers),
        'rest_api_count': len(rest_advertisers),
        'source': 'combined'
    }

def get_more_advertisers_via_products(max_products=500):
    """
    é€šè¿‡å¤§é‡å•†å“æŸ¥è¯¢è·å–æ›´å¤šå¹¿å‘Šå•†ä¿¡æ¯
    
    Args:
        max_products (int): æœ€å¤§æŸ¥è¯¢å•†å“æ•°é‡
        
    Returns:
        dict: å¹¿å‘Šå•†åˆ—è¡¨
    """
    # æ„å»ºGraphQLæŸ¥è¯¢ - è·å–å¤§é‡å•†å“æ¥è¦†ç›–æ›´å¤šå¹¿å‘Šå•†
    query = f"""
    {{
      products(companyId: "{COMPANY_ID}", limit: {max_products}) {{
        totalCount
        count
        resultList {{
          advertiserId
          advertiserName
          brand
          price {{
            amount
            currency
          }}
          title
        }}
      }}
    }}
    """
    
    headers = {
        'Authorization': f'Bearer {CJ_API_TOKEN}',
        'Content-Type': 'application/json'
    }
    
    body = json.dumps({'query': query})
    
    try:
        logger.info(f'æ­£åœ¨é€šè¿‡å¤§é‡å•†å“æŸ¥è¯¢è·å–å¹¿å‘Šå•†ä¿¡æ¯ (æœ€å¤š {max_products} ä¸ªå•†å“)...')
        
        response = requests.post(CJ_API_ENDPOINT, headers=headers, data=body)
        response.raise_for_status()
        
        json_data = response.json()
        
        if json_data and 'data' in json_data and 'products' in json_data['data']:
            products_data = json_data['data']['products']
            all_products = products_data.get('resultList', [])
            
            logger.info(f'ä»APIè·å–åˆ° {len(all_products)} ä¸ªå•†å“ï¼Œå¼€å§‹æå–å¹¿å‘Šå•†ä¿¡æ¯...')
            
            # æå–å”¯ä¸€çš„å¹¿å‘Šå•†ä¿¡æ¯ï¼Œæ”¶é›†æ›´å¤šç»Ÿè®¡æ•°æ®
            advertisers_dict = {}
            for product in all_products:
                advertiser_id = product.get('advertiserId')
                advertiser_name = product.get('advertiserName')
                brand = product.get('brand')
                price_info = product.get('price', {})
                
                if advertiser_id and advertiser_name:
                    if advertiser_id not in advertisers_dict:
                        advertisers_dict[advertiser_id] = {
                            'id': advertiser_id,
                            'name': advertiser_name,
                            'brands': set(),
                            'product_count': 0,
                            'sample_products': [],
                            'price_range': {'min': float('inf'), 'max': 0}
                        }
                    
                    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                    adv_info = advertisers_dict[advertiser_id]
                    adv_info['product_count'] += 1
                    
                    # æ·»åŠ å“ç‰Œä¿¡æ¯
                    if brand and brand != advertiser_name:
                        adv_info['brands'].add(brand)
                    
                    # æ”¶é›†æ ·å“å•†å“
                    if len(adv_info['sample_products']) < 3:
                        adv_info['sample_products'].append(product.get('title', ''))
                    
                    # æ›´æ–°ä»·æ ¼èŒƒå›´
                    if price_info and price_info.get('amount'):
                        try:
                            price = float(price_info['amount'])
                            adv_info['price_range']['min'] = min(adv_info['price_range']['min'], price)
                            adv_info['price_range']['max'] = max(adv_info['price_range']['max'], price)
                        except (ValueError, TypeError):
                            pass
            
            # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
            advertisers_list = []
            for advertiser_info in advertisers_dict.values():
                # å¤„ç†ä»·æ ¼èŒƒå›´
                if advertiser_info['price_range']['min'] == float('inf'):
                    advertiser_info['price_range'] = None
                else:
                    price_range = advertiser_info['price_range']
                    advertiser_info['price_range'] = f"${price_range['min']:.2f} - ${price_range['max']:.2f}"
                
                # è½¬æ¢setä¸ºlist
                advertiser_info['brands'] = list(advertiser_info['brands'])
                advertisers_list.append(advertiser_info)
            
            # æŒ‰å•†å“æ•°é‡æ’åº
            advertisers_list.sort(key=lambda x: x['product_count'], reverse=True)
            
            logger.info(f'æˆåŠŸæå–åˆ° {len(advertisers_list)} ä¸ªå¹¿å‘Šå•†çš„è¯¦ç»†ä¿¡æ¯')
            
            return {
                'advertisers': advertisers_list,
                'total_count': len(advertisers_list),
                'total_products_scanned': len(all_products),
                'source': 'products_detailed'
            }
        else:
            error_info = json_data.get('errors') if json_data else "No data returned"
            logger.error(f'è·å–å•†å“æ•°æ®å¤±è´¥ã€‚é”™è¯¯: {error_info}')
            return {'advertisers': [], 'total_count': 0, 'source': 'products_detailed', 'error': str(error_info)}
            
    except requests.exceptions.RequestException as error:
        logger.error(f'é€šè¿‡å•†å“æŸ¥è¯¢è·å–å¹¿å‘Šå•†ä¿¡æ¯å‡ºé”™: {error}')
        return {'advertisers': [], 'total_count': 0, 'source': 'products_detailed', 'error': str(error)}

def get_program_terms_and_publishers():
    """
    æŸ¥è¯¢CJ GraphQL APIçš„å¯ç”¨å­—æ®µï¼Œç„¶åè·å–å‘å¸ƒå•†ä¿¡æ¯
    
    Returns:
        dict: å‘å¸ƒå•†å’Œè®¡åˆ’æ¡æ¬¾ä¿¡æ¯
    """
    # é¦–å…ˆæŸ¥è¯¢APIçš„å¯ç”¨å­—æ®µ
    schema_query = """
    {
      __schema {
        queryType {
          fields {
            name
            description
            args {
              name
              type {
                name
                kind
              }
            }
          }
        }
      }
    }
    """
    
    headers = {
        'Authorization': f'Bearer {CJ_API_TOKEN}',
        'Content-Type': 'application/json'
    }
    
    try:
        logger.info('æ­£åœ¨æŸ¥è¯¢CJ GraphQL APIå¯ç”¨å­—æ®µ...')
        
        # é¦–å…ˆè·å–API schema
        schema_body = json.dumps({'query': schema_query})
        response = requests.post(CJ_API_ENDPOINT, headers=headers, data=schema_body)
        response.raise_for_status()
        
        schema_data = response.json()
        available_fields = []
        
        if schema_data and 'data' in schema_data and '__schema' in schema_data['data']:
            query_fields = schema_data['data']['__schema']['queryType']['fields']
            available_fields = [field['name'] for field in query_fields]
            logger.info(f'å‘ç°å¯ç”¨çš„GraphQLå­—æ®µ: {", ".join(available_fields[:10])}...')
        
        # ä½¿ç”¨å·²çŸ¥å¯ç”¨çš„productså­—æ®µè·å–è¯¦ç»†çš„å¹¿å‘Šå•†ä¿¡æ¯
        detailed_query = f"""
        {{
          products(companyId: "{COMPANY_ID}", limit: 300) {{
            totalCount
            count
            resultList {{
              advertiserId
              advertiserName
              brand
              title
              price {{
                amount
                currency
              }}
              link
              lastUpdated
            }}
          }}
        }}
        """
        
        logger.info('æ­£åœ¨é€šè¿‡productså­—æ®µè·å–å‘å¸ƒå•†ä¿¡æ¯...')
        products_body = json.dumps({'query': detailed_query})
        response = requests.post(CJ_API_ENDPOINT, headers=headers, data=products_body)
        response.raise_for_status()
        
        json_data = response.json()
        
        if json_data and 'data' in json_data and 'products' in json_data['data']:
            products_data = json_data['data']['products']
            all_products = products_data.get('resultList', [])
            
            logger.info(f'ä»products APIè·å–åˆ° {len(all_products)} ä¸ªå•†å“ï¼Œåˆ†æå‘å¸ƒå•†ä¿¡æ¯...')
            
            # åˆ†æå‘å¸ƒå•†ä¿¡æ¯
            publishers_dict = {}
            for product in all_products:
                advertiser_id = product.get('advertiserId')
                advertiser_name = product.get('advertiserName')
                
                if advertiser_id and advertiser_name:
                    if advertiser_id not in publishers_dict:
                        publishers_dict[advertiser_id] = {
                            'advertiser_id': advertiser_id,
                            'advertiser_name': advertiser_name,
                            'product_count': 0,
                            'brands': set(),
                            'price_range': {'min': float('inf'), 'max': 0},
                            'sample_products': [],
                            'last_updated': product.get('lastUpdated', ''),
                            'sample_links': []
                        }
                    
                    pub_info = publishers_dict[advertiser_id]
                    pub_info['product_count'] += 1
                    
                    # æ”¶é›†å“ç‰Œ
                    if product.get('brand'):
                        pub_info['brands'].add(product.get('brand'))
                    
                    # æ”¶é›†ä»·æ ¼ä¿¡æ¯
                    price_info = product.get('price', {})
                    if price_info and price_info.get('amount'):
                        try:
                            price = float(price_info['amount'])
                            pub_info['price_range']['min'] = min(pub_info['price_range']['min'], price)
                            pub_info['price_range']['max'] = max(pub_info['price_range']['max'], price)
                        except (ValueError, TypeError):
                            pass
                    
                    # æ”¶é›†æ ·å“ä¿¡æ¯
                    if len(pub_info['sample_products']) < 5:
                        pub_info['sample_products'].append(product.get('title', ''))
                    if len(pub_info['sample_links']) < 3:
                        pub_info['sample_links'].append(product.get('link', ''))
            
            # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ ¼å¼åŒ–
            publishers_list = []
            for pub_info in publishers_dict.values():
                # å¤„ç†ä»·æ ¼èŒƒå›´
                if pub_info['price_range']['min'] == float('inf'):
                    pub_info['price_range'] = 'N/A'
                else:
                    price_range = pub_info['price_range']
                    pub_info['price_range'] = f"${price_range['min']:.2f} - ${price_range['max']:.2f}"
                
                # è½¬æ¢å“ç‰Œé›†åˆä¸ºåˆ—è¡¨
                pub_info['brands'] = list(pub_info['brands'])
                
                publishers_list.append(pub_info)
            
            # æŒ‰äº§å“æ•°é‡æ’åº
            publishers_list.sort(key=lambda x: x['product_count'], reverse=True)
            
            logger.info(f'æˆåŠŸåˆ†æ {len(publishers_list)} ä¸ªå‘å¸ƒå•†çš„è¯¦ç»†ä¿¡æ¯')
            
            return {
                'publishers': publishers_list,
                'total_count': len(publishers_list),
                'total_products_analyzed': len(all_products),
                'available_fields': available_fields,
                'source': 'products_analysis'
            }
        else:
            error_info = json_data.get('errors') if json_data else "No data returned"
            logger.error(f'ProductsæŸ¥è¯¢å¤±è´¥ã€‚é”™è¯¯: {error_info}')
            return {'publishers': [], 'total_count': 0, 'source': 'products_analysis', 'error': str(error_info)}
            
    except requests.exceptions.RequestException as error:
        logger.error(f'å‘å¸ƒå•†ä¿¡æ¯æŸ¥è¯¢å‡ºé”™: {error}')
        if hasattr(error, 'response'):
            logger.error(f'APIå“åº”çŠ¶æ€: {error.response.status_code}')
            try:
                logger.error(f'APIè¿”å›çš„é”™è¯¯è¯¦æƒ…: {json.dumps(error.response.json(), indent=2, ensure_ascii=False)}')
            except:
                logger.error(f'APIè¿”å›çš„åŸå§‹å†…å®¹: {error.response.text}')
        return {'publishers': [], 'total_count': 0, 'source': 'products_analysis', 'error': str(error)}

def save_to_json_file(data, filename):
    """
    å°†æ•°æ®ä¿å­˜ä¸ºJSONæ–‡ä»¶
    
    Args:
        data (dict): è¦ä¿å­˜çš„æ•°æ®
        filename (str): æ–‡ä»¶å
    """
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = Path('output')
    output_dir.mkdir(exist_ok=True)
    
    # æ·»åŠ æ—¶é—´æˆ³åˆ°æ–‡ä»¶å
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    file_path = output_dir / f"{timestamp}_{filename}"
    
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    
    logger.info(f'æ•°æ®å·²ä¿å­˜åˆ° {file_path}')
    # è¿”å›ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ï¼Œä»¥ä¾¿äºå…¶ä»–åœ°æ–¹ä½¿ç”¨
    return file_path

def main():
    """ä¸»å‡½æ•°: å‘½ä»¤è¡Œå…¥å£ç‚¹"""
    parser = argparse.ArgumentParser(description='CJå•†å“æŸ¥è¯¢å·¥å…·')
    subparsers = parser.add_subparsers(dest='command', help='å­å‘½ä»¤')
    
    # å¹¿å‘Šå•†å•†å“å­å‘½ä»¤
    advertiser_parser = subparsers.add_parser('advertiser', help='è·å–æŒ‡å®šå¹¿å‘Šå•†çš„å•†å“')
    advertiser_parser.add_argument('advertiser_id', help='å¹¿å‘Šå•†ID')
    advertiser_parser.add_argument('--limit', type=int, default=50, help='è¿”å›ç»“æœæ•°é‡é™åˆ¶ (é»˜è®¤: 50)')
    
    # æœç´¢å•†å“å­å‘½ä»¤
    search_parser = subparsers.add_parser('search', help='æœç´¢å•†å“')
    search_parser.add_argument('keyword', help='æœç´¢å…³é”®è¯')
    search_parser.add_argument('--limit', type=int, default=50, help='è¿”å›ç»“æœæ•°é‡é™åˆ¶ (é»˜è®¤: 50)')
    
    # å·²åŠ å…¥å¹¿å‘Šå•†å­å‘½ä»¤
    joined_parser = subparsers.add_parser('joined', help='è·å–å·²åŠ å…¥å¹¿å‘Šå•†çš„å•†å“')
    joined_parser.add_argument('--limit', type=int, default=50, help='è¿”å›ç»“æœæ•°é‡é™åˆ¶ (é»˜è®¤: 50)')
    
    # å¹¿å‘Šå•†åˆ—è¡¨å­å‘½ä»¤
    advertisers_parser = subparsers.add_parser('advertisers', help='åˆ—å‡ºå·²åŠ å…¥çš„å¹¿å‘Šå•†')
    advertisers_parser.add_argument('--limit', type=int, default=100, help='è¿”å›ç»“æœæ•°é‡é™åˆ¶ (é»˜è®¤: 100)')
    
    # Program Termså‘å¸ƒå•†æŸ¥è¯¢å­å‘½ä»¤
    publishers_parser = subparsers.add_parser('publishers', help='é€šè¿‡Program TermsæŸ¥è¯¢å‘å¸ƒå•†ä¿¡æ¯')
    publishers_parser.add_argument('--save-details', action='store_true', help='ä¿å­˜è¯¦ç»†çš„ä½£é‡‘å’Œæ¿€åŠ±ä¿¡æ¯')
    
    args = parser.parse_args()
    
    try:
        if args.command == 'advertiser':
            logger.info(f'å¼€å§‹è·å–å¹¿å‘Šå•† {args.advertiser_id} çš„å•†å“ (é™åˆ¶: {args.limit})...')
            data = get_products_by_advertiser(args.advertiser_id, args.limit)
            
            if data and 'data' in data and 'products' in data['data']:
                products_data = data['data']['products']
                logger.info(f'æˆåŠŸè·å–åˆ° {products_data["count"]} ä¸ªå•†å“ï¼Œæ€»å…± {products_data["totalCount"]} ä¸ª')
                
                if products_data['count'] > 0:
                    logger.info(f'å‰5ä¸ªå•†å“åˆ—è¡¨:')
                    for i, product in enumerate(products_data['resultList'][:5]):
                        price_display = f"{product['price']['amount']} {product['price']['currency']}" if product.get('price') else 'ä»·æ ¼ä¸å¯ç”¨'
                        logger.info(f"{i + 1}. {product['title']} - {price_display}")
                    
                    output_file = save_to_json_file(data, f"advertiser_{args.advertiser_id}_products.json")
                    logger.info(f'å®Œæ•´å•†å“æ•°æ®å·²ä¿å­˜åˆ°: {output_file}')
                else:
                    logger.warning(f'å¹¿å‘Šå•† {args.advertiser_id} æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å•†å“ã€‚')
            elif data and 'errors' in data:
                logger.error(f'GraphQL æŸ¥è¯¢è¿”å›é”™è¯¯: {json.dumps(data["errors"], indent=2, ensure_ascii=False)}')
            else:
                logger.warning('æœªä» API è·å–åˆ°æœ‰æ•ˆçš„å•†å“æ•°æ®ç»“æ„ã€‚')
                logger.debug(f'æ”¶åˆ°çš„æ•°æ®: {json.dumps(data, indent=2, ensure_ascii=False)}')
        
        elif args.command == 'search':
            logger.info(f'å¼€å§‹æœç´¢å…³é”®è¯ "{args.keyword}" çš„å•†å“ (é™åˆ¶: {args.limit})...')
            data = search_products(args.keyword, args.limit)
            
            products_data = data.get('data', {}).get('products', {})
            logger.info(f'æˆåŠŸæœç´¢åˆ° {products_data.get("count", 0)} ä¸ªå•†å“ï¼Œæ€»å…± {products_data.get("totalCount", 0)} ä¸ª')
            
            if products_data.get('count', 0) > 0:
                logger.info(f'å‰5ä¸ªæœç´¢ç»“æœ:')
                for i, product in enumerate(products_data['resultList'][:5]):
                    price = product.get('price', {})
                    price_display = f"{price.get('amount')} {price.get('currency')}" if price else 'ä»·æ ¼ä¸å¯ç”¨'
                    logger.info(f"{i + 1}. {product['title']} - {price_display}")
                
                output_file = save_to_json_file(data, f"search_{args.keyword}_products.json")
                logger.info(f'å®Œæ•´æœç´¢ç»“æœå·²ä¿å­˜åˆ°: {output_file}')
            else:
                logger.warning(f'æœªæ‰¾åˆ°ä¸ "{args.keyword}" åŒ¹é…çš„å•†å“ã€‚')
        
        elif args.command == 'joined':
            logger.info(f'å¼€å§‹è·å–å·²åŠ å…¥å¹¿å‘Šå•†çš„å•†å“ (é™åˆ¶: {args.limit})...')
            data = get_joined_advertiser_products(args.limit)
            
            products_data = data.get('data', {}).get('products', {})
            logger.info(f'æˆåŠŸè·å–åˆ° {products_data.get("count", 0)} ä¸ªå•†å“ï¼Œæ€»å…± {products_data.get("totalCount", 0)} ä¸ª')
            
            if products_data.get('count', 0) > 0:
                logger.info(f'å‰5ä¸ªå·²åŠ å…¥å¹¿å‘Šå•†çš„å•†å“:')
                for i, product in enumerate(products_data['resultList'][:5]):
                    price = product.get('price', {})
                    price_display = f"{price.get('amount')} {price.get('currency')}" if price else 'ä»·æ ¼ä¸å¯ç”¨'
                    logger.info(f"{i + 1}. {product['title']} - {price_display}")
                
                timestamp = datetime.now().strftime('%Y-%m-%d')
                output_file = save_to_json_file(data, f"joined_products_{timestamp}.json")
                logger.info(f'å®Œæ•´å•†å“æ•°æ®å·²ä¿å­˜åˆ°: {output_file}')
            else:
                logger.warning('æœªæ‰¾åˆ°å·²åŠ å…¥å¹¿å‘Šå•†çš„å•†å“ã€‚')
        
        elif args.command == 'advertisers':
            logger.info(f'å¼€å§‹è·å–å·²åŠ å…¥çš„å¹¿å‘Šå•†åˆ—è¡¨ (é™åˆ¶: {args.limit})...')
            # ä½¿ç”¨æ–°çš„è¯¦ç»†æ–¹æ³•è·å–æ›´å¤šå¹¿å‘Šå•†ä¿¡æ¯
            data = get_more_advertisers_via_products(args.limit * 5)
            
            advertisers = data.get('advertisers', [])
            total_count = data.get('total_count', 0)
            
            if total_count > 0:
                # æ˜¾ç¤ºæ•°æ®æºä¿¡æ¯
                source_info = ""
                if 'total_products_scanned' in data:
                    source_info = f"(æ‰«æäº† {data['total_products_scanned']} ä¸ªå•†å“)"
                elif 'graphql_count' in data:
                    source_info = f"GraphQL: {data.get('graphql_count', 0)}, REST API: {data.get('rest_api_count', 0)}"
                
                logger.info(f'å·²åŠ å…¥çš„å¹¿å‘Šå•†åˆ—è¡¨ (å…± {total_count} ä¸ª) {source_info}')
                logger.info('=' * 80)
                
                for i, advertiser in enumerate(advertisers, 1):
                    logger.info(f"{i:2d}. å¹¿å‘Šå•†ID: {advertiser['id']}")
                    logger.info(f"    å¹¿å‘Šå•†åç§°: {advertiser['name']}")
                    
                    # æ˜¾ç¤ºå•†å“æ•°é‡ï¼ˆå¦‚æœæœ‰ï¼‰
                    if 'product_count' in advertiser:
                        logger.info(f"    å•†å“æ•°é‡: {advertiser['product_count']}")
                    
                    # æ˜¾ç¤ºå“ç‰Œä¿¡æ¯
                    if advertiser.get('brands'):
                        brands_str = ', '.join(advertiser['brands'])
                        logger.info(f"    æ——ä¸‹å“ç‰Œ: {brands_str}")
                    
                    # æ˜¾ç¤ºä»·æ ¼èŒƒå›´
                    if advertiser.get('price_range'):
                        logger.info(f"    ä»·æ ¼èŒƒå›´: {advertiser['price_range']}")
                    
                    # æ˜¾ç¤ºæ ·å“å•†å“
                    if advertiser.get('sample_products'):
                        sample_str = ', '.join(advertiser['sample_products'][:2])
                        logger.info(f"    æ ·å“å•†å“: {sample_str}...")
                    
                    # æ˜¾ç¤ºå…¶ä»–ä¿¡æ¯
                    if advertiser.get('category'):
                        logger.info(f"    ç±»åˆ«: {advertiser['category']}")
                    if advertiser.get('seven_day_epc'):
                        logger.info(f"    7å¤©EPC: {advertiser['seven_day_epc']}")
                    if advertiser.get('three_month_epc'):
                        logger.info(f"    3æœˆEPC: {advertiser['three_month_epc']}")
                    
                    logger.info('-' * 60)
                
                # ä¿å­˜å¹¿å‘Šå•†åˆ—è¡¨åˆ°æ–‡ä»¶
                timestamp = datetime.now().strftime('%Y-%m-%d')
                output_file = save_to_json_file(data, f"advertisers_list_{timestamp}.json")
                logger.info(f'å¹¿å‘Šå•†åˆ—è¡¨å·²ä¿å­˜åˆ°: {output_file}')
            else:
                logger.warning('æœªæ‰¾åˆ°å·²åŠ å…¥çš„å¹¿å‘Šå•†ã€‚')
        
        elif args.command == 'publishers':
            logger.info('å¼€å§‹é€šè¿‡Program TermsæŸ¥è¯¢å‘å¸ƒå•†ä¿¡æ¯...')
            data = get_program_terms_and_publishers()
            
            publishers = data.get('publishers', [])
            total_count = data.get('total_count', 0)
            
            if total_count > 0:
                products_analyzed = data.get('total_products_analyzed', 0)
                logger.info(f'é€šè¿‡å•†å“åˆ†æè·å–åˆ°çš„å‘å¸ƒå•†ä¿¡æ¯ (å…± {total_count} ä¸ªï¼Œåˆ†æäº† {products_analyzed} ä¸ªå•†å“):')
                logger.info('=' * 100)
                
                for i, publisher in enumerate(publishers, 1):
                    logger.info(f"{i:2d}. å¹¿å‘Šå•†ID: {publisher['advertiser_id']}")
                    logger.info(f"    å¹¿å‘Šå•†åç§°: {publisher['advertiser_name']}")
                    logger.info(f"    å•†å“æ•°é‡: {publisher['product_count']}")
                    
                    # æ˜¾ç¤ºä»·æ ¼èŒƒå›´
                    if publisher.get('price_range') and publisher['price_range'] != 'N/A':
                        logger.info(f"    ä»·æ ¼èŒƒå›´: {publisher['price_range']}")
                    
                    # æ˜¾ç¤ºå“ç‰Œä¿¡æ¯
                    if publisher.get('brands'):
                        brands_str = ', '.join(publisher['brands'][:3])
                        if len(publisher['brands']) > 3:
                            brands_str += f' (+{len(publisher["brands"]) - 3} æ›´å¤š)'
                        logger.info(f"    ç›¸å…³å“ç‰Œ: {brands_str}")
                    
                    # æ˜¾ç¤ºæ ·å“å•†å“
                    if publisher.get('sample_products'):
                        samples = publisher['sample_products'][:3]
                        samples_str = ', '.join(samples)
                        if len(publisher['sample_products']) > 3:
                            samples_str += '...'
                        logger.info(f"    æ ·å“å•†å“: {samples_str}")
                    
                    # æ˜¾ç¤ºæœ€åæ›´æ–°æ—¶é—´
                    if publisher.get('last_updated'):
                        logger.info(f"    æœ€åæ›´æ–°: {publisher['last_updated']}")
                    
                    # æ˜¾ç¤ºæ ·å“é“¾æ¥
                    if publisher.get('sample_links') and args.save_details:
                        logger.info(f"    æ ·å“é“¾æ¥æ•°é‡: {len(publisher['sample_links'])}")
                    
                    logger.info('-' * 80)
                
                # ä¿å­˜å‘å¸ƒå•†ä¿¡æ¯åˆ°æ–‡ä»¶
                timestamp = datetime.now().strftime('%Y-%m-%d')
                filename_suffix = "detailed" if args.save_details else "summary"
                output_file = save_to_json_file(data, f"publishers_program_terms_{filename_suffix}_{timestamp}.json")
                logger.info(f'å‘å¸ƒå•†ä¿¡æ¯å·²ä¿å­˜åˆ°: {output_file}')
                
                # æ˜¾ç¤ºæ±‡æ€»ç»Ÿè®¡
                logger.info(f'\nğŸ“Š å‘å¸ƒå•†ç»Ÿè®¡æ±‡æ€»:')
                logger.info(f'   æ€»å‘å¸ƒå•†æ•°é‡: {total_count}')
                
                # ç»Ÿè®¡å…³ç³»çŠ¶æ€
                status_counts = {}
                for pub in publishers:
                    status = pub.get('relationship_status', 'Unknown')
                    status_counts[status] = status_counts.get(status, 0) + 1
                
                logger.info(f'   å…³ç³»çŠ¶æ€åˆ†å¸ƒ:')
                for status, count in status_counts.items():
                    logger.info(f'     {status}: {count}')
                
            else:
                logger.warning('æœªæ‰¾åˆ°å‘å¸ƒå•†ä¿¡æ¯ã€‚')
                if 'error' in data:
                    logger.error(f'é”™è¯¯è¯¦æƒ…: {data["error"]}')
        else:
            logger.error('è¯·æŒ‡å®šæœ‰æ•ˆçš„å­å‘½ä»¤ã€‚ä½¿ç”¨ -h æŸ¥çœ‹å¸®åŠ©ã€‚')
            parser.print_help()
    
    except Exception as e:
        logger.error(f'æ‰§è¡Œå¤±è´¥: {e}', exc_info=True)  # ä½¿ç”¨exc_infoå‚æ•°è®°å½•å †æ ˆè·Ÿè¸ª
        # æˆ‘ä»¬ä¸å†éœ€è¦æ‰‹åŠ¨æ‰“å°tracebackï¼Œå› ä¸ºlogging.errorå¸¦exc_info=Trueä¼šè‡ªåŠ¨åŒ…å«å †æ ˆä¿¡æ¯
        # ä½†å¦‚æœç‰¹åˆ«éœ€è¦ï¼Œå¯ä»¥è®©tracebackè¾“å‡ºæ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        # import traceback
        # logger.debug(f'è¯¦ç»†é”™è¯¯: {traceback.format_exc()}')

if __name__ == '__main__':
    main() 